,Model,Validation F1,Test F1,Classification Report
0,bert,0.899880345513478,0.896860345513478,"              precision    recall  f1-score   support

           0       0.97      0.96      0.97       362
           1       0.90      0.89      0.90       377
           2       0.80      0.78      0.79       267
           3       0.92      0.92      0.92       356
           4       0.89      0.92      0.91       250
           5       0.91      0.89      0.90       375
           6       0.84      0.89      0.86       253

    accuracy                           0.90      2240
   macro avg       0.89      0.89      0.89      2240
weighted avg       0.90      0.90      0.90      2240
"
1,distilbert,0.89964812308625,0.89274812308625,"              precision    recall  f1-score   support

           0       0.98      0.97      0.97       362
           1       0.89      0.88      0.89       377
           2       0.79      0.76      0.77       267
           3       0.91      0.92      0.92       356
           4       0.89      0.90      0.90       250
           5       0.91      0.88      0.90       375
           6       0.83      0.91      0.87       253

    accuracy                           0.89      2240
   macro avg       0.89      0.89      0.89      2240
weighted avg       0.89      0.89      0.89      2240
"
2,roberta,0.899636473169235,0.894636473169235,"              precision    recall  f1-score   support

           0       0.98      0.95      0.96       362
           1       0.91      0.90      0.91       377
           2       0.78      0.79      0.79       267
           3       0.91      0.93      0.92       356
           4       0.88      0.90      0.89       250
           5       0.92      0.88      0.90       375
           6       0.83      0.88      0.86       253

    accuracy                           0.89      2240
   macro avg       0.89      0.89      0.89      2240
weighted avg       0.90      0.89      0.89      2240
"
3,xlm-roberta,0.90910283862448,0.89910283862448,"              precision    recall  f1-score   support

           0       0.98      0.96      0.97       362
           1       0.91      0.89      0.90       377
           2       0.80      0.78      0.79       267
           3       0.91      0.93      0.92       356
           4       0.88      0.89      0.89       250
           5       0.91      0.90      0.91       375
           6       0.86      0.90      0.88       253

    accuracy                           0.90      2240
   macro avg       0.89      0.89      0.89      2240
weighted avg       0.90      0.90      0.90      2240
"
